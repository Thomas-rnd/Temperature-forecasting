{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:18:26.217539200Z",
     "start_time": "2023-11-30T10:18:19.741226700Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:18:26.225726300Z",
     "start_time": "2023-11-30T10:18:26.225726300Z"
    }
   },
   "id": "2f176304f9d29dd3"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class CustomDataLoader:\n",
    "    def __init__(self, feature_path, files_path):\n",
    "        self.feature_path = feature_path\n",
    "        self.files_path = files_path\n",
    "\n",
    "    def load_and_split_data(self):\n",
    "        try:\n",
    "            # Load and concatenate the CSV files\n",
    "            df_list = [pd.read_csv(os.path.join(feature_path,file)) for file in file_paths]\n",
    "            data = pd.concat(df_list, ignore_index=True)\n",
    "            logging.info(\"Data loaded successfully.\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading data: {e}\")\n",
    "            raise"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:18:26.255112200Z",
     "start_time": "2023-11-30T10:18:26.225726300Z"
    }
   },
   "id": "2721344149d0f91d"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def preprocess(self):\n",
    "        # Drop the column named 'g'\n",
    "        if 'g' in self.data.columns:\n",
    "            logging.info(\"Drop column 'g'.\")\n",
    "            self.data.drop('g', axis=1, inplace=True)\n",
    "        \n",
    "        # Drop the column named 'sst'\n",
    "        if 'sst' in self.data.columns:\n",
    "            logging.info(\"Drop column 'sst'.\")\n",
    "            self.data.drop('sst', axis=1, inplace=True)\n",
    "        \n",
    "        logging.info(\"Changing time to datetime format.\")\n",
    "        if 'time' in self.data.columns:\n",
    "            self.data['time'] = pd.to_datetime(self.data['time']).astype('int64') // 10**9\n",
    "        \n",
    "        # Drop rows with any NaN values\n",
    "        logging.info(\"Drop NaN rows.\")\n",
    "        self.data.dropna(inplace=True)\n",
    "        logging.info(\"Data preprocessing completed.\")\n",
    "        return self.data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:18:26.279902Z",
     "start_time": "2023-11-30T10:18:26.257643600Z"
    }
   },
   "id": "7756be953e831a44"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        \"\"\"\n",
    "        Custom Dataset compatible with PyTorch DataLoader.\n",
    "        :param features: Pandas DataFrame or NumPy array containing the features.\n",
    "        :param targets: Pandas Series or NumPy array containing the targets.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.features = torch.tensor(features.values, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(targets.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:18:26.279902Z",
     "start_time": "2023-11-30T10:18:26.259745300Z"
    }
   },
   "id": "76ec92f1e8db95ce"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class DataSplitter:\n",
    "    def __init__(self, data, target_name='2t', test_size=0.2, val_size=0.1, batch_size=32):\n",
    "        self.data = data\n",
    "        self.target_name = target_name\n",
    "        self.test_size = test_size\n",
    "        self.val_size = val_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def split_data(self):\n",
    "        X = self.data.drop(self.target_name, axis=1)\n",
    "        y = self.data[self.target_name]\n",
    "\n",
    "        # Splitting the data\n",
    "        X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=self.test_size, random_state=42)\n",
    "        val_size_adjusted = self.val_size / (1 - self.test_size)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=val_size_adjusted, random_state=42)\n",
    "\n",
    "        # Creating Dataset objects\n",
    "        train_dataset = CustomDataset(X_train, y_train)\n",
    "        val_dataset = CustomDataset(X_val, y_val)\n",
    "        test_dataset = CustomDataset(X_test, y_test)\n",
    "\n",
    "        # Creating DataLoader objects\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        return train_loader, val_loader, test_loader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:18:26.313146300Z",
     "start_time": "2023-11-30T10:18:26.288908900Z"
    }
   },
   "id": "c2419e211ae52a39"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def log_combined_data_loader_info(train_loader, val_loader, test_loader):\n",
    "    \"\"\"\n",
    "    Logs combined information about the Train, Validation, and Test DataLoaders in a tabular format,\n",
    "    including the percentage of each dataset.\n",
    "    :param train_loader: PyTorch DataLoader for the training set.\n",
    "    :param val_loader: PyTorch DataLoader for the validation set.\n",
    "    :param test_loader: PyTorch DataLoader for the test set.\n",
    "    \"\"\"\n",
    "    # Gathering information\n",
    "    total_samples_each = [len(train_loader.dataset), len(val_loader.dataset), len(test_loader.dataset)]\n",
    "    total_samples_all = sum(total_samples_each)\n",
    "    percentages = [(samples / total_samples_all) * 100 for samples in total_samples_each]\n",
    "\n",
    "    info = {\n",
    "        \"Set\": [\"Train\", \"Validation\", \"Test\"],\n",
    "        \"Total Batches\": [len(train_loader), len(val_loader), len(test_loader)],\n",
    "        \"Batch Size\": [train_loader.batch_size, val_loader.batch_size, test_loader.batch_size],\n",
    "        \"Total Samples\": total_samples_each,\n",
    "        \"Percentage\": percentages\n",
    "    }\n",
    "\n",
    "    # Creating a formatted string to represent the table\n",
    "    table_header = f\"{'Set':<12}{'Total Batches':<15}{'Batch Size':<12}{'Total Samples':<15}{'Percentage':<10}\"\n",
    "    table_rows = [f\"{set_name:<12}{batches:<15}{batch_size:<12}{samples:<15}{percent:.2f}%\" \n",
    "                  for set_name, batches, batch_size, samples, percent in zip(info[\"Set\"], info[\"Total Batches\"], info[\"Batch Size\"], info[\"Total Samples\"], info[\"Percentage\"])]\n",
    "\n",
    "    table = \"\\n\".join([table_header] + table_rows)\n",
    "\n",
    "    # Logging the table\n",
    "    logging.info(\"\\n\" + table)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d82e4b4f573fcf3"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class PyTorchModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(PyTorchModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:18:26.313146300Z",
     "start_time": "2023-11-30T10:18:26.296301600Z"
    }
   },
   "id": "f301490b824c51bf"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class ModelBuilder:\n",
    "    def build_model(self, input_size):\n",
    "        model = PyTorchModel(input_size)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        criterion = nn.MSELoss()\n",
    "        logging.info(f\"PyTorch model built successfully. Optimizer: {optimizer}, Loss: {criterion}\")\n",
    "        return model, optimizer, criterion"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:18:26.313146300Z",
     "start_time": "2023-11-30T10:18:26.305012500Z"
    }
   },
   "id": "a88e146d23f3e434"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, optimizer, criterion, train_csv, test_csv, batch_size=32, epochs=10):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Load datasets\n",
    "        self.train_data = CustomWeatherDataset(csv_file=train_csv)\n",
    "        self.test_data = CustomWeatherDataset(csv_file=test_csv)\n",
    "\n",
    "        # Create data loaders\n",
    "        self.train_loader = DataLoader(self.train_data, batch_size=self.batch_size, shuffle=True)\n",
    "        self.test_loader = DataLoader(self.test_data, batch_size=self.batch_size)\n",
    "\n",
    "        logging.info(\"Data loaders created successfully.\")\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "        for epoch in range(self.epochs):\n",
    "            running_loss = 0.0\n",
    "            for features, labels in self.train_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(features)\n",
    "                loss = self.criterion(outputs.squeeze(), labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            average_loss = running_loss / len(self.train_loader)\n",
    "            logging.info(f\"Epoch {epoch+1}/{self.epochs}, Loss: {average_loss:.4f}\")\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for features, labels in self.test_loader:\n",
    "                outputs = self.model(features)\n",
    "                loss = self.criterion(outputs.squeeze(), labels)\n",
    "                total_loss += loss.item()\n",
    "        average_loss = total_loss / len(self.test_loader)\n",
    "        logging.info(f\"Test Loss: {average_loss:.4f}\")\n",
    "\n",
    "    def visualize_batch(self):\n",
    "        train_features, train_labels = next(iter(self.train_loader))\n",
    "        logging.info(f\"Feature batch shape: {train_features.size()}\")\n",
    "        logging.info(f\"Labels batch shape: {train_labels.size()}\")\n",
    "        example_features = train_features[0]\n",
    "        example_label = train_labels[0]\n",
    "        plt.plot(example_features.numpy(), label='Features')\n",
    "        plt.title(f'Example Weather Data Features with Label: {example_label.item()}')\n",
    "        plt.xlabel('Feature Index')\n",
    "        plt.ylabel('Feature Value')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:18:26.344486800Z",
     "start_time": "2023-11-30T10:18:26.320655Z"
    }
   },
   "id": "f6e0c1ef75396798"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class PredictionVisualizer:\n",
    "    def __init__(self, model, data):\n",
    "        self.model = model\n",
    "        self.data = data\n",
    "\n",
    "    def visualize_future_forecast(self, future_data):\n",
    "        predictions = self.model.predict(future_data)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(predictions)\n",
    "        plt.title(\"Future Temperature Forecast\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Temperature\")\n",
    "        plt.savefig(\"future_forecast.png\")\n",
    "        plt.show()\n",
    "\n",
    "    def compare_actual_vs_predicted(self, test_data):\n",
    "        actual = test_data['target']\n",
    "        predicted = self.model.predict(test_data.drop('target', axis=1))\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(actual, label='Actual')\n",
    "        plt.plot(predicted, label='Predicted')\n",
    "        plt.title(\"Comparison of Actual vs Predicted Temperatures\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Temperature\")\n",
    "        plt.legend()\n",
    "        plt.savefig(\"actual_vs_predicted.png\")\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:18:26.344486800Z",
     "start_time": "2023-11-30T10:18:26.336572600Z"
    }
   },
   "id": "171982e690287aba"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class ReportGenerator:\n",
    "    def __init__(self, actual, predicted):\n",
    "        self.actual = actual\n",
    "        self.predicted = predicted\n",
    "\n",
    "    def generate_report(self):\n",
    "        report_df = pd.DataFrame({\n",
    "            'Actual': self.actual,\n",
    "            'Predicted': self.predicted.squeeze(),\n",
    "            'Difference': self.actual - self.predicted.squeeze()\n",
    "        })\n",
    "        report_df['Error'] = report_df['Difference'].abs()\n",
    "        report_df['Squared Error'] = report_df['Error'] ** 2\n",
    "\n",
    "        # Additional statistics\n",
    "        report_df['Mean Actual'] = self.actual.mean()\n",
    "        report_df['Mean Predicted'] = self.predicted.mean()\n",
    "        report_df['Standard Deviation Actual'] = self.actual.std()\n",
    "        report_df['Standard Deviation Predicted'] = self.predicted.std()\n",
    "\n",
    "        report_df.to_csv('report.csv', index=False)\n",
    "        logging.info(\"Report generated and saved as report.csv.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:18:26.368381800Z",
     "start_time": "2023-11-30T10:18:26.352493900Z"
    }
   },
   "id": "b8aa38d7d4259fa0"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:18:26.368381800Z",
     "start_time": "2023-11-30T10:18:26.355240100Z"
    }
   },
   "id": "d8c801bdf0d251a2"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#wwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww#\n",
    "########################################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:18:26.368381800Z",
     "start_time": "2023-11-30T10:18:26.367354100Z"
    }
   },
   "id": "1db8a5273f1aec20"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:18:26.384260700Z",
     "start_time": "2023-11-30T10:18:26.378254500Z"
    }
   },
   "id": "59d792097968baa4"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "feature_path = 'features_selection/data'\n",
    "file_paths = ['features_0_19402023.csv', 'features_1_19402023.csv', \n",
    "              'features_2_19402023.csv', 'features_3_19402023.csv',\n",
    "              'features_4_19402023.csv']\n",
    "\n",
    "# Initialize DataLoader and split data\n",
    "data_loader = CustomDataLoader(feature_path,file_paths)\n",
    "data = data_loader.load_and_split_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:18:33.229923Z",
     "start_time": "2023-11-30T10:18:26.384260700Z"
    }
   },
   "id": "f54da26663e889b4"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Drop column 'g'.\n",
      "INFO:root:Drop column 'sst'.\n",
      "INFO:root:Changing time to datetime format.\n",
      "INFO:root:Drop NaN rows.\n",
      "INFO:root:Data preprocessing completed.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data\n",
    "preprocessor = DataPreprocessor(data)\n",
    "data = preprocessor.preprocess()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:18:34.427566600Z",
     "start_time": "2023-11-30T10:18:33.218912500Z"
    }
   },
   "id": "9bda1a9c69bf194f"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "               time  latitude  longitude        10u       10v       100u  \\\n0        -946771200      38.0     125.00   0.419251 -6.994049   0.539322   \n1        -946771200      38.0     125.25   0.267883 -5.567291   0.401627   \n2        -946771200      38.0     125.50   0.320618 -4.622955   0.482681   \n3        -946771200      38.0     125.75   0.107727 -4.240143   0.275650   \n4        -946771200      38.0     126.00   0.156555 -3.693268   0.290298   \n...             ...       ...        ...        ...       ...        ...   \n3594271  1700395200      34.0     129.00  10.564636 -3.080109  11.930634   \n3594272  1700395200      34.0     129.25  10.969910 -2.972687  12.307587   \n3594273  1700395200      34.0     129.50  10.767761 -2.702179  12.258759   \n3594274  1700395200      34.0     129.75  11.442566 -2.366242  12.838837   \n3594275  1700395200      34.0     130.00  11.910339 -2.254913  13.131805   \n\n             100v         msl     swvl1     geo500         2t  \n0       -7.767197  102701.690  0.000002  54024.832  -2.504486  \n1       -6.972275  102700.440  0.182467  54007.832  -4.463470  \n2       -6.185165  102706.690  0.229876  53989.582  -6.065033  \n3       -5.673447  102706.190  0.208132  53971.082  -6.861908  \n4       -5.080673  102703.690  0.293429  53953.582  -7.449799  \n...           ...         ...       ...        ...        ...  \n3594271 -3.466751  101845.875  0.000005  55508.690  16.389801  \n3594272 -3.304642  101832.625  0.000005  55488.190  16.299957  \n3594273 -3.010696  101818.625  0.000005  55467.940  16.333160  \n3594274 -2.653275  101801.625  0.000005  55448.690  16.514801  \n3594275 -2.496048  101784.125  0.000005  55427.190  16.676910  \n\n[3594276 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>10u</th>\n      <th>10v</th>\n      <th>100u</th>\n      <th>100v</th>\n      <th>msl</th>\n      <th>swvl1</th>\n      <th>geo500</th>\n      <th>2t</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-946771200</td>\n      <td>38.0</td>\n      <td>125.00</td>\n      <td>0.419251</td>\n      <td>-6.994049</td>\n      <td>0.539322</td>\n      <td>-7.767197</td>\n      <td>102701.690</td>\n      <td>0.000002</td>\n      <td>54024.832</td>\n      <td>-2.504486</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-946771200</td>\n      <td>38.0</td>\n      <td>125.25</td>\n      <td>0.267883</td>\n      <td>-5.567291</td>\n      <td>0.401627</td>\n      <td>-6.972275</td>\n      <td>102700.440</td>\n      <td>0.182467</td>\n      <td>54007.832</td>\n      <td>-4.463470</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-946771200</td>\n      <td>38.0</td>\n      <td>125.50</td>\n      <td>0.320618</td>\n      <td>-4.622955</td>\n      <td>0.482681</td>\n      <td>-6.185165</td>\n      <td>102706.690</td>\n      <td>0.229876</td>\n      <td>53989.582</td>\n      <td>-6.065033</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-946771200</td>\n      <td>38.0</td>\n      <td>125.75</td>\n      <td>0.107727</td>\n      <td>-4.240143</td>\n      <td>0.275650</td>\n      <td>-5.673447</td>\n      <td>102706.190</td>\n      <td>0.208132</td>\n      <td>53971.082</td>\n      <td>-6.861908</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-946771200</td>\n      <td>38.0</td>\n      <td>126.00</td>\n      <td>0.156555</td>\n      <td>-3.693268</td>\n      <td>0.290298</td>\n      <td>-5.080673</td>\n      <td>102703.690</td>\n      <td>0.293429</td>\n      <td>53953.582</td>\n      <td>-7.449799</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3594271</th>\n      <td>1700395200</td>\n      <td>34.0</td>\n      <td>129.00</td>\n      <td>10.564636</td>\n      <td>-3.080109</td>\n      <td>11.930634</td>\n      <td>-3.466751</td>\n      <td>101845.875</td>\n      <td>0.000005</td>\n      <td>55508.690</td>\n      <td>16.389801</td>\n    </tr>\n    <tr>\n      <th>3594272</th>\n      <td>1700395200</td>\n      <td>34.0</td>\n      <td>129.25</td>\n      <td>10.969910</td>\n      <td>-2.972687</td>\n      <td>12.307587</td>\n      <td>-3.304642</td>\n      <td>101832.625</td>\n      <td>0.000005</td>\n      <td>55488.190</td>\n      <td>16.299957</td>\n    </tr>\n    <tr>\n      <th>3594273</th>\n      <td>1700395200</td>\n      <td>34.0</td>\n      <td>129.50</td>\n      <td>10.767761</td>\n      <td>-2.702179</td>\n      <td>12.258759</td>\n      <td>-3.010696</td>\n      <td>101818.625</td>\n      <td>0.000005</td>\n      <td>55467.940</td>\n      <td>16.333160</td>\n    </tr>\n    <tr>\n      <th>3594274</th>\n      <td>1700395200</td>\n      <td>34.0</td>\n      <td>129.75</td>\n      <td>11.442566</td>\n      <td>-2.366242</td>\n      <td>12.838837</td>\n      <td>-2.653275</td>\n      <td>101801.625</td>\n      <td>0.000005</td>\n      <td>55448.690</td>\n      <td>16.514801</td>\n    </tr>\n    <tr>\n      <th>3594275</th>\n      <td>1700395200</td>\n      <td>34.0</td>\n      <td>130.00</td>\n      <td>11.910339</td>\n      <td>-2.254913</td>\n      <td>13.131805</td>\n      <td>-2.496048</td>\n      <td>101784.125</td>\n      <td>0.000005</td>\n      <td>55427.190</td>\n      <td>16.676910</td>\n    </tr>\n  </tbody>\n</table>\n<p>3594276 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:18:34.459222700Z",
     "start_time": "2023-11-30T10:18:34.427566600Z"
    }
   },
   "id": "8a57ef7c10ef2951"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "Set         Total Batches  Batch Size  Total Samples  Percentage\n",
      "Train       78625          32          2515992        70.00%\n",
      "Validation  11233          32          359428         10.00%\n",
      "Test        22465          32          718856         20.00%\n"
     ]
    }
   ],
   "source": [
    "splitter = DataSplitter(data, batch_size=32)\n",
    "train, validation, test = splitter.split_data()\n",
    "log_combined_data_loader_info(train, validation, test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:34:07.551403100Z",
     "start_time": "2023-11-30T10:34:04.829891400Z"
    }
   },
   "id": "7363a41c960bc718"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build and train the model\n",
    "builder = ModelBuilder()\n",
    "model, optimizer, criterion = builder.build_model(input_size)\n",
    "trainer = Trainer(model, optimizer, criterion, train_data, val_data, test_data, batch_size=32, epochs=10)\n",
    "trainer.train()\n",
    "trainer.evaluate()\n",
    "\n",
    "# Visualization and report generation (optional)\n",
    "# These steps would require additional data or modifications\n",
    "# depending on your specific use case and available data\n",
    "\n",
    "# Example usage (modify as needed):\n",
    "# visualizer = PredictionVisualizer(model, processed_data)\n",
    "# future_data = ... # Load or create your future data for prediction\n",
    "# visualizer.visualize_future_forecast(future_data)\n",
    "# test_data = ... # Subset of processed_data or separate test data\n",
    "# visualizer.compare_actual_vs_predicted(test_data)\n",
    "\n",
    "# Generate report (modify as needed):\n",
    "# actual_values = ... # Actual values from your dataset\n",
    "# predicted_values = model.predict(...) # Predictions from your model\n",
    "# report_generator = ReportGenerator(actual_values, predicted_values)\n",
    "# report_generator.generate_report()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T10:18:37.616524400Z"
    }
   },
   "id": "6449d568eeee74d5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T10:18:37.621033600Z",
     "start_time": "2023-11-30T10:18:37.621033600Z"
    }
   },
   "id": "f3bd5898aadd81de"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
